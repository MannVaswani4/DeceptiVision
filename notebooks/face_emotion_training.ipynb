{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fafd929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from src.models.face_cnn import FaceCNN\n",
    "from src.video_to_frames import extract_frames\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "465804ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"../data/raw/fer2013/train\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(\"../data/raw/fer2013/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classes:\", train_data.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb22840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.6935\n",
      "Epoch 2 | Loss: 1.4555\n",
      "Epoch 3 | Loss: 1.3263\n",
      "Epoch 4 | Loss: 1.2478\n",
      "Epoch 5 | Loss: 1.1782\n",
      "Epoch 6 | Loss: 1.1170\n",
      "Epoch 7 | Loss: 1.0583\n",
      "Epoch 8 | Loss: 0.9998\n",
      "Epoch 9 | Loss: 0.9388\n",
      "Epoch 10 | Loss: 0.8854\n",
      "✅ Model saved!\n"
     ]
    }
   ],
   "source": [
    "model = FaceCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model ONCE\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/emotion_cnn.pth\")\n",
    "print(\"✅ Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "143a345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded for inference\n"
     ]
    }
   ],
   "source": [
    "model = FaceCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"../models/emotion_cnn.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"✅ Model loaded for inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd2389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(frame_path):\n",
    "    img = Image.open(frame_path)\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "        probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2c3cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved 52 frames to ../data/frames/trial_lie_041.mp4\n",
      "✅ Processed trial_lie_041.mp4 (lie)\n",
      " Saved 64 frames to ../data/frames/trial_lie_055.mp4\n",
      "✅ Processed trial_lie_055.mp4 (lie)\n",
      " Saved 40 frames to ../data/frames/trial_lie_054.mp4\n",
      "✅ Processed trial_lie_054.mp4 (lie)\n",
      " Saved 50 frames to ../data/frames/trial_lie_040.mp4\n",
      "✅ Processed trial_lie_040.mp4 (lie)\n",
      " Saved 63 frames to ../data/frames/trial_lie_056.mp4\n",
      "✅ Processed trial_lie_056.mp4 (lie)\n",
      " Saved 48 frames to ../data/frames/trial_lie_042.mp4\n",
      "✅ Processed trial_lie_042.mp4 (lie)\n",
      " Saved 29 frames to ../data/frames/trial_lie_043.mp4\n",
      "✅ Processed trial_lie_043.mp4 (lie)\n",
      " Saved 41 frames to ../data/frames/trial_lie_057.mp4\n",
      "✅ Processed trial_lie_057.mp4 (lie)\n",
      " Saved 72 frames to ../data/frames/trial_lie_053.mp4\n",
      "✅ Processed trial_lie_053.mp4 (lie)\n",
      " Saved 35 frames to ../data/frames/trial_lie_047.mp4\n",
      "✅ Processed trial_lie_047.mp4 (lie)\n",
      " Saved 71 frames to ../data/frames/trial_lie_046.mp4\n",
      "✅ Processed trial_lie_046.mp4 (lie)\n",
      " Saved 96 frames to ../data/frames/trial_lie_052.mp4\n",
      "✅ Processed trial_lie_052.mp4 (lie)\n",
      " Saved 20 frames to ../data/frames/trial_lie_044.mp4\n",
      "✅ Processed trial_lie_044.mp4 (lie)\n",
      " Saved 50 frames to ../data/frames/trial_lie_050.mp4\n",
      "✅ Processed trial_lie_050.mp4 (lie)\n",
      " Saved 14 frames to ../data/frames/trial_lie_051.mp4\n",
      "✅ Processed trial_lie_051.mp4 (lie)\n",
      " Saved 41 frames to ../data/frames/trial_lie_045.mp4\n",
      "✅ Processed trial_lie_045.mp4 (lie)\n",
      " Saved 89 frames to ../data/frames/trial_lie_022.mp4\n",
      "✅ Processed trial_lie_022.mp4 (lie)\n",
      " Saved 84 frames to ../data/frames/trial_lie_036.mp4\n",
      "✅ Processed trial_lie_036.mp4 (lie)\n",
      " Saved 54 frames to ../data/frames/trial_lie_037.mp4\n",
      "✅ Processed trial_lie_037.mp4 (lie)\n",
      " Saved 93 frames to ../data/frames/trial_lie_023.mp4\n",
      "✅ Processed trial_lie_023.mp4 (lie)\n",
      " Saved 70 frames to ../data/frames/trial_lie_035.mp4\n",
      "✅ Processed trial_lie_035.mp4 (lie)\n",
      " Saved 39 frames to ../data/frames/trial_lie_021.mp4\n",
      "✅ Processed trial_lie_021.mp4 (lie)\n",
      " Saved 45 frames to ../data/frames/trial_lie_009.mp4\n",
      "✅ Processed trial_lie_009.mp4 (lie)\n",
      " Saved 16 frames to ../data/frames/trial_lie_008.mp4\n",
      "✅ Processed trial_lie_008.mp4 (lie)\n",
      " Saved 24 frames to ../data/frames/trial_lie_020.mp4\n",
      "✅ Processed trial_lie_020.mp4 (lie)\n",
      " Saved 63 frames to ../data/frames/trial_lie_034.mp4\n",
      "✅ Processed trial_lie_034.mp4 (lie)\n",
      " Saved 74 frames to ../data/frames/trial_lie_018.mp4\n",
      "✅ Processed trial_lie_018.mp4 (lie)\n",
      " Saved 81 frames to ../data/frames/trial_lie_030.mp4\n",
      "✅ Processed trial_lie_030.mp4 (lie)\n",
      " Saved 53 frames to ../data/frames/trial_lie_024.mp4\n",
      "✅ Processed trial_lie_024.mp4 (lie)\n",
      " Saved 64 frames to ../data/frames/trial_lie_025.mp4\n",
      "✅ Processed trial_lie_025.mp4 (lie)\n",
      " Saved 56 frames to ../data/frames/trial_lie_031.mp4\n",
      "✅ Processed trial_lie_031.mp4 (lie)\n",
      " Saved 79 frames to ../data/frames/trial_lie_019.mp4\n",
      "✅ Processed trial_lie_019.mp4 (lie)\n",
      " Saved 58 frames to ../data/frames/trial_lie_027.mp4\n",
      "✅ Processed trial_lie_027.mp4 (lie)\n",
      " Saved 94 frames to ../data/frames/trial_lie_033.mp4\n",
      "✅ Processed trial_lie_033.mp4 (lie)\n",
      " Saved 59 frames to ../data/frames/trial_lie_032.mp4\n",
      "✅ Processed trial_lie_032.mp4 (lie)\n",
      " Saved 62 frames to ../data/frames/trial_lie_026.mp4\n",
      "✅ Processed trial_lie_026.mp4 (lie)\n",
      " Saved 16 frames to ../data/frames/trial_lie_003.mp4\n",
      "✅ Processed trial_lie_003.mp4 (lie)\n",
      " Saved 94 frames to ../data/frames/trial_lie_017.mp4\n",
      "✅ Processed trial_lie_017.mp4 (lie)\n",
      " Saved 80 frames to ../data/frames/trial_lie_016.mp4\n",
      "✅ Processed trial_lie_016.mp4 (lie)\n",
      " Saved 134 frames to ../data/frames/trial_lie_002.mp4\n",
      "✅ Processed trial_lie_002.mp4 (lie)\n",
      " Saved 30 frames to ../data/frames/trial_lie_014.mp4\n",
      "✅ Processed trial_lie_014.mp4 (lie)\n",
      " Saved 52 frames to ../data/frames/trial_lie_028.mp4\n",
      "✅ Processed trial_lie_028.mp4 (lie)\n",
      " Saved 43 frames to ../data/frames/trial_lie_029.mp4\n",
      "✅ Processed trial_lie_029.mp4 (lie)\n",
      " Saved 37 frames to ../data/frames/trial_lie_001.mp4\n",
      "✅ Processed trial_lie_001.mp4 (lie)\n",
      " Saved 74 frames to ../data/frames/trial_lie_015.mp4\n",
      "✅ Processed trial_lie_015.mp4 (lie)\n",
      " Saved 63 frames to ../data/frames/trial_lie_039.mp4\n",
      "✅ Processed trial_lie_039.mp4 (lie)\n",
      " Saved 73 frames to ../data/frames/trial_lie_011.mp4\n",
      "✅ Processed trial_lie_011.mp4 (lie)\n",
      " Saved 115 frames to ../data/frames/trial_lie_005.mp4\n",
      "✅ Processed trial_lie_005.mp4 (lie)\n",
      " Saved 25 frames to ../data/frames/trial_lie_004.mp4\n",
      "✅ Processed trial_lie_004.mp4 (lie)\n",
      " Saved 63 frames to ../data/frames/trial_lie_010.mp4\n",
      "✅ Processed trial_lie_010.mp4 (lie)\n",
      " Saved 48 frames to ../data/frames/trial_lie_038.mp4\n",
      "✅ Processed trial_lie_038.mp4 (lie)\n",
      " Saved 39 frames to ../data/frames/trial_lie_006.mp4\n",
      "✅ Processed trial_lie_006.mp4 (lie)\n",
      " Saved 17 frames to ../data/frames/trial_lie_012.mp4\n",
      "✅ Processed trial_lie_012.mp4 (lie)\n",
      " Saved 41 frames to ../data/frames/trial_lie_013.mp4\n",
      "✅ Processed trial_lie_013.mp4 (lie)\n",
      " Saved 101 frames to ../data/frames/trial_lie_007.mp4\n",
      "✅ Processed trial_lie_007.mp4 (lie)\n",
      " Saved 54 frames to ../data/frames/trial_lie_060.mp4\n",
      "✅ Processed trial_lie_060.mp4 (lie)\n",
      " Saved 103 frames to ../data/frames/trial_lie_048.mp4\n",
      "✅ Processed trial_lie_048.mp4 (lie)\n",
      " Saved 50 frames to ../data/frames/trial_lie_049.mp4\n",
      "✅ Processed trial_lie_049.mp4 (lie)\n",
      " Saved 63 frames to ../data/frames/trial_lie_061.mp4\n",
      "✅ Processed trial_lie_061.mp4 (lie)\n",
      " Saved 86 frames to ../data/frames/trial_lie_059.mp4\n",
      "✅ Processed trial_lie_059.mp4 (lie)\n",
      " Saved 48 frames to ../data/frames/trial_lie_058.mp4\n",
      "✅ Processed trial_lie_058.mp4 (lie)\n",
      " Saved 73 frames to ../data/frames/trial_truth_056.mp4\n",
      "✅ Processed trial_truth_056.mp4 (truth)\n",
      " Saved 60 frames to ../data/frames/trial_truth_042.mp4\n",
      "✅ Processed trial_truth_042.mp4 (truth)\n",
      " Saved 44 frames to ../data/frames/trial_truth_043.mp4\n",
      "✅ Processed trial_truth_043.mp4 (truth)\n",
      " Saved 82 frames to ../data/frames/trial_truth_057.mp4\n",
      "✅ Processed trial_truth_057.mp4 (truth)\n",
      " Saved 68 frames to ../data/frames/trial_truth_041.mp4\n",
      "✅ Processed trial_truth_041.mp4 (truth)\n",
      " Saved 63 frames to ../data/frames/trial_truth_055.mp4\n",
      "✅ Processed trial_truth_055.mp4 (truth)\n",
      " Saved 52 frames to ../data/frames/trial_truth_054.mp4\n",
      "✅ Processed trial_truth_054.mp4 (truth)\n",
      " Saved 65 frames to ../data/frames/trial_truth_040.mp4\n",
      "✅ Processed trial_truth_040.mp4 (truth)\n",
      " Saved 42 frames to ../data/frames/trial_truth_044.mp4\n",
      "✅ Processed trial_truth_044.mp4 (truth)\n",
      " Saved 46 frames to ../data/frames/trial_truth_050.mp4\n",
      "✅ Processed trial_truth_050.mp4 (truth)\n",
      " Saved 63 frames to ../data/frames/trial_truth_051.mp4\n",
      "✅ Processed trial_truth_051.mp4 (truth)\n",
      " Saved 66 frames to ../data/frames/trial_truth_045.mp4\n",
      "✅ Processed trial_truth_045.mp4 (truth)\n",
      " Saved 63 frames to ../data/frames/trial_truth_053.mp4\n",
      "✅ Processed trial_truth_053.mp4 (truth)\n",
      " Saved 52 frames to ../data/frames/trial_truth_047.mp4\n",
      "✅ Processed trial_truth_047.mp4 (truth)\n",
      " Saved 74 frames to ../data/frames/trial_truth_046.mp4\n",
      "✅ Processed trial_truth_046.mp4 (truth)\n",
      " Saved 58 frames to ../data/frames/trial_truth_052.mp4\n",
      "✅ Processed trial_truth_052.mp4 (truth)\n",
      " Saved 63 frames to ../data/frames/trial_truth_035.mp4\n",
      "✅ Processed trial_truth_035.mp4 (truth)\n",
      " Saved 22 frames to ../data/frames/trial_truth_021.mp4\n",
      "✅ Processed trial_truth_021.mp4 (truth)\n",
      " Saved 49 frames to ../data/frames/trial_truth_009.mp4\n",
      "✅ Processed trial_truth_009.mp4 (truth)\n",
      " Saved 95 frames to ../data/frames/trial_truth_008.mp4\n",
      "✅ Processed trial_truth_008.mp4 (truth)\n",
      " Saved 15 frames to ../data/frames/trial_truth_020.mp4\n",
      "✅ Processed trial_truth_020.mp4 (truth)\n",
      " Saved 65 frames to ../data/frames/trial_truth_034.mp4\n",
      "✅ Processed trial_truth_034.mp4 (truth)\n",
      " Saved 62 frames to ../data/frames/trial_truth_022.mp4\n",
      "✅ Processed trial_truth_022.mp4 (truth)\n",
      " Saved 78 frames to ../data/frames/trial_truth_036.mp4\n",
      "✅ Processed trial_truth_036.mp4 (truth)\n",
      " Saved 46 frames to ../data/frames/trial_truth_037.mp4\n",
      "✅ Processed trial_truth_037.mp4 (truth)\n",
      " Saved 49 frames to ../data/frames/trial_truth_023.mp4\n",
      "✅ Processed trial_truth_023.mp4 (truth)\n",
      " Saved 54 frames to ../data/frames/trial_truth_027.mp4\n",
      "✅ Processed trial_truth_027.mp4 (truth)\n",
      " Saved 36 frames to ../data/frames/trial_truth_033.mp4\n",
      "✅ Processed trial_truth_033.mp4 (truth)\n",
      " Saved 78 frames to ../data/frames/trial_truth_032.mp4\n",
      "✅ Processed trial_truth_032.mp4 (truth)\n",
      " Saved 69 frames to ../data/frames/trial_truth_026.mp4\n",
      "✅ Processed trial_truth_026.mp4 (truth)\n",
      " Saved 15 frames to ../data/frames/trial_truth_018.mp4\n",
      "✅ Processed trial_truth_018.mp4 (truth)\n",
      " Saved 115 frames to ../data/frames/trial_truth_030.mp4\n",
      "✅ Processed trial_truth_030.mp4 (truth)\n",
      " Saved 48 frames to ../data/frames/trial_truth_024.mp4\n",
      "✅ Processed trial_truth_024.mp4 (truth)\n",
      " Saved 73 frames to ../data/frames/trial_truth_025.mp4\n",
      "✅ Processed trial_truth_025.mp4 (truth)\n",
      " Saved 38 frames to ../data/frames/trial_truth_031.mp4\n",
      "✅ Processed trial_truth_031.mp4 (truth)\n",
      " Saved 28 frames to ../data/frames/trial_truth_019.mp4\n",
      "✅ Processed trial_truth_019.mp4 (truth)\n",
      " Saved 28 frames to ../data/frames/trial_truth_014.mp4\n",
      "✅ Processed trial_truth_014.mp4 (truth)\n",
      " Saved 38 frames to ../data/frames/trial_truth_028.mp4\n",
      "✅ Processed trial_truth_028.mp4 (truth)\n",
      " Saved 48 frames to ../data/frames/trial_truth_029.mp4\n",
      "✅ Processed trial_truth_029.mp4 (truth)\n",
      " Saved 30 frames to ../data/frames/trial_truth_001.mp4\n",
      "✅ Processed trial_truth_001.mp4 (truth)\n",
      " Saved 77 frames to ../data/frames/trial_truth_015.mp4\n",
      "✅ Processed trial_truth_015.mp4 (truth)\n",
      " Saved 28 frames to ../data/frames/trial_truth_003.mp4\n",
      "✅ Processed trial_truth_003.mp4 (truth)\n",
      " Saved 10 frames to ../data/frames/trial_truth_017.mp4\n",
      "✅ Processed trial_truth_017.mp4 (truth)\n",
      " Saved 16 frames to ../data/frames/trial_truth_016.mp4\n",
      "✅ Processed trial_truth_016.mp4 (truth)\n",
      " Saved 43 frames to ../data/frames/trial_truth_002.mp4\n",
      "✅ Processed trial_truth_002.mp4 (truth)\n",
      " Saved 66 frames to ../data/frames/trial_truth_006.mp4\n",
      "✅ Processed trial_truth_006.mp4 (truth)\n",
      " Saved 61 frames to ../data/frames/trial_truth_012.mp4\n",
      "✅ Processed trial_truth_012.mp4 (truth)\n",
      " Saved 60 frames to ../data/frames/trial_truth_013.mp4\n",
      "✅ Processed trial_truth_013.mp4 (truth)\n",
      " Saved 154 frames to ../data/frames/trial_truth_007.mp4\n",
      "✅ Processed trial_truth_007.mp4 (truth)\n",
      " Saved 67 frames to ../data/frames/trial_truth_039.mp4\n",
      "✅ Processed trial_truth_039.mp4 (truth)\n",
      " Saved 88 frames to ../data/frames/trial_truth_011.mp4\n",
      "✅ Processed trial_truth_011.mp4 (truth)\n",
      " Saved 75 frames to ../data/frames/trial_truth_005.mp4\n",
      "✅ Processed trial_truth_005.mp4 (truth)\n",
      " Saved 175 frames to ../data/frames/trial_truth_004.mp4\n",
      "✅ Processed trial_truth_004.mp4 (truth)\n",
      " Saved 155 frames to ../data/frames/trial_truth_010.mp4\n",
      "✅ Processed trial_truth_010.mp4 (truth)\n",
      " Saved 40 frames to ../data/frames/trial_truth_038.mp4\n",
      "✅ Processed trial_truth_038.mp4 (truth)\n",
      " Saved 42 frames to ../data/frames/trial_truth_060.mp4\n",
      "✅ Processed trial_truth_060.mp4 (truth)\n",
      " Saved 52 frames to ../data/frames/trial_truth_048.mp4\n",
      "✅ Processed trial_truth_048.mp4 (truth)\n",
      " Saved 60 frames to ../data/frames/trial_truth_049.mp4\n",
      "✅ Processed trial_truth_049.mp4 (truth)\n",
      " Saved 58 frames to ../data/frames/trial_truth_059.mp4\n",
      "✅ Processed trial_truth_059.mp4 (truth)\n",
      " Saved 45 frames to ../data/frames/trial_truth_058.mp4\n",
      "✅ Processed trial_truth_058.mp4 (truth)\n"
     ]
    }
   ],
   "source": [
    "video_root = \"../videos\"\n",
    "for class_name in [\"lie\", \"truth\"]:\n",
    "    label = 0 if class_name == \"lie\" else 1\n",
    "    folder = os.path.join(video_root, class_name)\n",
    "\n",
    "    for video_file in os.listdir(folder):\n",
    "        video_path = os.path.join(folder, video_file)\n",
    "        frame_dir  = f\"../data/frames/{video_file}\"\n",
    "        extract_frames(video_path, frame_dir, fps=2)\n",
    "\n",
    "        frames = sorted(os.listdir(frame_dir))\n",
    "        timeline = np.array([predict_emotion(f\"{frame_dir}/{f}\") for f in frames])\n",
    "\n",
    "        dominant = np.argmax(timeline, 1)\n",
    "        unique, counts = np.unique(dominant, return_counts=True)\n",
    "        ratio = dict(zip([labels[u] for u in unique], counts/len(dominant)))\n",
    "\n",
    "        transitions = np.sum(dominant[:-1] != dominant[1:])\n",
    "        volatility  = np.mean(np.abs(np.diff(timeline, axis=0)))\n",
    "        peak   = dict(zip(labels, timeline.max(0)))\n",
    "        var    = dict(zip(labels, timeline.var(0)))\n",
    "\n",
    "        features = []\n",
    "        for e in labels: features.append(ratio.get(e,0))\n",
    "        features += [transitions, volatility]\n",
    "        for e in labels: features.append(peak[e])\n",
    "        for e in labels: features.append(var[e])\n",
    "\n",
    "        row = list(np.array(features, dtype=np.float32)) + [label]\n",
    "\n",
    "        with open(\"../data/deception_dataset.csv\",\"a\") as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "\n",
    "        print(f\"✅ Processed {video_file} ({class_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf269ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved to dataset\n"
     ]
    }
   ],
   "source": [
    "row = list(X_sample) + [label]\n",
    "file = \"../data/deception_dataset.csv\"\n",
    "header = [f\"f{i}\" for i in range(23)] + [\"label\"]\n",
    "\n",
    "if not os.path.exists(file):\n",
    "    with open(file, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow(header)\n",
    "\n",
    "with open(file, \"a\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow(row)\n",
    "\n",
    "print(\"✅ saved to dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7f7be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Trained!\n",
      "\n",
      "Accuracy: 0.76\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        15\n",
      "           1       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.76      0.77      0.76        25\n",
      "weighted avg       0.77      0.76      0.76        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/deception_dataset.csv\")\n",
    "\n",
    "# Separate features & labels\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test performance\n",
    "preds = clf.predict(X_test)\n",
    "print(\"✅ Model Trained!\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e3ef288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lie/Truth classifier saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"../models/deception_classifier.pkl\")\n",
    "print(\"✅ Lie/Truth classifier saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21c22551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: LIE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "clf = joblib.load(\"../models/deception_classifier.pkl\")\n",
    "\n",
    "# Convert X_sample to DataFrame with same column names as training data\n",
    "X_input = pd.DataFrame([X_sample], columns=clf.feature_names_in_)\n",
    "\n",
    "prediction = clf.predict(X_input)\n",
    "print(\"Prediction:\", \"LIE\" if prediction[0] == 0 else \"TRUTH\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
