{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafd929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from src.models.face_cnn import FaceCNN\n",
    "from src.video_to_frames import extract_frames\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "465804ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"../data/raw/fer2013/train\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(\"../data/raw/fer2013/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=32, shuffle=False)\n",
    "\n",
    "emotion_labels = train_data.classes  \n",
    "\n",
    "print(\"Classes:\", train_data.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb22840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.6563\n",
      "Epoch 2 | Loss: 1.4267\n",
      "Epoch 3 | Loss: 1.2978\n",
      "Epoch 4 | Loss: 1.1960\n",
      "Epoch 5 | Loss: 1.1062\n",
      "Epoch 6 | Loss: 1.0275\n",
      "Epoch 7 | Loss: 0.9518\n",
      "Epoch 8 | Loss: 0.8694\n",
      "Epoch 9 | Loss: 0.7849\n",
      "Epoch 10 | Loss: 0.7100\n",
      "✅ Model saved!\n"
     ]
    }
   ],
   "source": [
    "model = FaceCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model ONCE\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/emotion_cnn.pth\")\n",
    "print(\"✅ Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143a345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded for inference\n"
     ]
    }
   ],
   "source": [
    "model = FaceCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"../models/emotion_cnn.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"✅ Model loaded for inference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(frame_path):\n",
    "    img = Image.open(frame_path)\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(img)\n",
    "        probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ca4b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.body_language_yolo import extract_yolo_pose     # <-- NEW\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def process_video_to_features(video_path, class_label, out_csv, fps=2):\n",
    "    \"\"\"\n",
    "    Extracts:\n",
    "        - Emotion timeline\n",
    "        - Body-language timeline (YOLO Pose)\n",
    "    Then creates:\n",
    "        - 23 emotion features\n",
    "        - 7 body-language features\n",
    "    Then writes one row to CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    video_name = Path(video_path).stem\n",
    "    frame_dir = Path(f\"../data/frames/{video_name}\")\n",
    "    frame_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Extract frames from video\n",
    "    extract_frames(str(video_path), str(frame_dir), fps=fps)\n",
    "\n",
    "    # List frames\n",
    "    frames = sorted([f for f in os.listdir(frame_dir) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        print(f\"⚠️ No frames extracted for {video_name}\")\n",
    "        return False\n",
    "\n",
    "    emotion_list = []\n",
    "    pose_list = []\n",
    "\n",
    "    # ------------ PER FRAME FEATURE EXTRACTION ------------\n",
    "    for f in frames:\n",
    "        frame_path = str(frame_dir / f)\n",
    "\n",
    "        # Emotion (your existing model)\n",
    "        emot = predict_emotion(frame_path)\n",
    "        emotion_list.append(emot)\n",
    "\n",
    "        # Pose keypoints (YOLOv8)\n",
    "        pose = extract_yolo_pose(frame_path)\n",
    "        pose_list.append(pose)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    emotion_timeline = np.array(emotion_list)   # (N_frames, 7)\n",
    "    pose_timeline = np.array(pose_list)         # (N_frames, 51)\n",
    "\n",
    "    # ------------ EMOTION FEATURES (YOUR EXISTING LOGIC) ------------\n",
    "    dominant = np.argmax(emotion_timeline, axis=1)\n",
    "    unique, counts = np.unique(dominant, return_counts=True)\n",
    "    ratios = {e: 0 for e in emotion_labels}\n",
    "    for idx, c in zip(unique, counts):\n",
    "        ratios[emotion_labels[idx]] = c / len(dominant)\n",
    "\n",
    "    transitions = int(np.sum(dominant[:-1] != dominant[1:]))\n",
    "    volatility = float(np.mean(np.abs(np.diff(emotion_timeline, axis=0))))\n",
    "\n",
    "    peak_vals = emotion_timeline.max(axis=0)\n",
    "    var_vals = emotion_timeline.var(axis=0)\n",
    "\n",
    "    emotion_features = []\n",
    "    for e in emotion_labels:\n",
    "        emotion_features.append(float(ratios[e]))\n",
    "\n",
    "    emotion_features += [float(transitions), float(volatility)]\n",
    "    emotion_features += [float(v) for v in peak_vals]\n",
    "    emotion_features += [float(v) for v in var_vals]\n",
    "\n",
    "    # ------------ BODY-LANGUAGE FEATURES (NEW) ------------\n",
    "    # movement intensity: frame-to-frame change of all keypoints\n",
    "    movement = np.linalg.norm(np.diff(pose_timeline, axis=0), axis=1)\n",
    "    movement_mean = float(movement.mean())\n",
    "    movement_var = float(movement.var())\n",
    "    movement_max = float(movement.max())\n",
    "\n",
    "    # shoulder width stability (keypoints 5 & 6)\n",
    "    left_shoulder  = pose_timeline[:, 5*3:5*3+2]\n",
    "    right_shoulder = pose_timeline[:, 6*3:6*3+2]\n",
    "    shoulder_dist = np.linalg.norm(left_shoulder - right_shoulder, axis=1)\n",
    "    shoulder_var = float(shoulder_dist.var())\n",
    "\n",
    "    # head movement (nose index = 0)\n",
    "    nose = pose_timeline[:, 0:3]\n",
    "    head_speed = np.linalg.norm(np.diff(nose, axis=0), axis=1)\n",
    "    head_var = float(head_speed.var())\n",
    "\n",
    "    # hand-to-face (keypoints 9=left wrist, 10=right wrist)\n",
    "    left_wrist = pose_timeline[:, 9*3:9*3+3]\n",
    "    right_wrist = pose_timeline[:, 10*3:10*3+3]\n",
    "    nose_3d = pose_timeline[:, 0:3]\n",
    "\n",
    "    lw_dist = np.linalg.norm(left_wrist - nose_3d, axis=1)\n",
    "    rw_dist = np.linalg.norm(right_wrist - nose_3d, axis=1)\n",
    "\n",
    "    hand_face_min = float(min(lw_dist.min(), rw_dist.min()))\n",
    "    hand_face_mean = float((lw_dist.mean() + rw_dist.mean()) / 2)\n",
    "\n",
    "    body_features = [\n",
    "        movement_mean, movement_var, movement_max,\n",
    "        shoulder_var, head_var,\n",
    "        hand_face_min, hand_face_mean\n",
    "    ]\n",
    "\n",
    "    # ------------ COMBINE ALL FEATURES ------------\n",
    "    features = emotion_features + body_features\n",
    "\n",
    "    # Write CSV header if necessary\n",
    "    header = [f\"f{i}\" for i in range(len(features))] + [\"label\"]\n",
    "    file_exists = os.path.exists(out_csv)\n",
    "\n",
    "    if not file_exists:\n",
    "        with open(out_csv, \"w\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(header)\n",
    "\n",
    "    # Write new row\n",
    "    row = features + [int(class_label)]\n",
    "    with open(out_csv, \"a\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow(row)\n",
    "\n",
    "    print(f\"✅ Processed {video_name} | Features: {len(features)} | Label: {class_label}\")\n",
    "    return features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c3cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 52 frames from ../videos/lie/trial_lie_041.mp4 → ../data/frames/trial_lie_041\n",
      "✅ Processed trial_lie_041 | Features: 30 | Label: 0\n",
      "✅ Extracted 64 frames from ../videos/lie/trial_lie_055.mp4 → ../data/frames/trial_lie_055\n",
      "✅ Processed trial_lie_055 | Features: 30 | Label: 0\n",
      "✅ Extracted 40 frames from ../videos/lie/trial_lie_054.mp4 → ../data/frames/trial_lie_054\n",
      "✅ Processed trial_lie_054 | Features: 30 | Label: 0\n",
      "✅ Extracted 50 frames from ../videos/lie/trial_lie_040.mp4 → ../data/frames/trial_lie_040\n",
      "✅ Processed trial_lie_040 | Features: 30 | Label: 0\n",
      "✅ Extracted 63 frames from ../videos/lie/trial_lie_056.mp4 → ../data/frames/trial_lie_056\n",
      "✅ Processed trial_lie_056 | Features: 30 | Label: 0\n",
      "✅ Extracted 48 frames from ../videos/lie/trial_lie_042.mp4 → ../data/frames/trial_lie_042\n",
      "✅ Processed trial_lie_042 | Features: 30 | Label: 0\n",
      "✅ Extracted 29 frames from ../videos/lie/trial_lie_043.mp4 → ../data/frames/trial_lie_043\n",
      "✅ Processed trial_lie_043 | Features: 30 | Label: 0\n",
      "✅ Extracted 41 frames from ../videos/lie/trial_lie_057.mp4 → ../data/frames/trial_lie_057\n",
      "✅ Processed trial_lie_057 | Features: 30 | Label: 0\n",
      "✅ Extracted 72 frames from ../videos/lie/trial_lie_053.mp4 → ../data/frames/trial_lie_053\n",
      "✅ Processed trial_lie_053 | Features: 30 | Label: 0\n",
      "✅ Extracted 35 frames from ../videos/lie/trial_lie_047.mp4 → ../data/frames/trial_lie_047\n",
      "✅ Processed trial_lie_047 | Features: 30 | Label: 0\n",
      "✅ Extracted 71 frames from ../videos/lie/trial_lie_046.mp4 → ../data/frames/trial_lie_046\n",
      "✅ Processed trial_lie_046 | Features: 30 | Label: 0\n",
      "✅ Extracted 96 frames from ../videos/lie/trial_lie_052.mp4 → ../data/frames/trial_lie_052\n",
      "✅ Processed trial_lie_052 | Features: 30 | Label: 0\n",
      "✅ Extracted 20 frames from ../videos/lie/trial_lie_044.mp4 → ../data/frames/trial_lie_044\n",
      "✅ Processed trial_lie_044 | Features: 30 | Label: 0\n",
      "✅ Extracted 50 frames from ../videos/lie/trial_lie_050.mp4 → ../data/frames/trial_lie_050\n",
      "✅ Processed trial_lie_050 | Features: 30 | Label: 0\n",
      "✅ Extracted 14 frames from ../videos/lie/trial_lie_051.mp4 → ../data/frames/trial_lie_051\n",
      "✅ Processed trial_lie_051 | Features: 30 | Label: 0\n",
      "✅ Extracted 41 frames from ../videos/lie/trial_lie_045.mp4 → ../data/frames/trial_lie_045\n",
      "✅ Processed trial_lie_045 | Features: 30 | Label: 0\n",
      "✅ Extracted 89 frames from ../videos/lie/trial_lie_022.mp4 → ../data/frames/trial_lie_022\n",
      "✅ Processed trial_lie_022 | Features: 30 | Label: 0\n",
      "✅ Extracted 84 frames from ../videos/lie/trial_lie_036.mp4 → ../data/frames/trial_lie_036\n",
      "✅ Processed trial_lie_036 | Features: 30 | Label: 0\n",
      "✅ Extracted 54 frames from ../videos/lie/trial_lie_037.mp4 → ../data/frames/trial_lie_037\n",
      "✅ Processed trial_lie_037 | Features: 30 | Label: 0\n",
      "✅ Extracted 93 frames from ../videos/lie/trial_lie_023.mp4 → ../data/frames/trial_lie_023\n",
      "✅ Processed trial_lie_023 | Features: 30 | Label: 0\n",
      "✅ Extracted 70 frames from ../videos/lie/trial_lie_035.mp4 → ../data/frames/trial_lie_035\n",
      "✅ Processed trial_lie_035 | Features: 30 | Label: 0\n",
      "✅ Extracted 39 frames from ../videos/lie/trial_lie_021.mp4 → ../data/frames/trial_lie_021\n",
      "✅ Processed trial_lie_021 | Features: 30 | Label: 0\n",
      "✅ Extracted 45 frames from ../videos/lie/trial_lie_009.mp4 → ../data/frames/trial_lie_009\n",
      "✅ Processed trial_lie_009 | Features: 30 | Label: 0\n",
      "✅ Extracted 16 frames from ../videos/lie/trial_lie_008.mp4 → ../data/frames/trial_lie_008\n",
      "✅ Processed trial_lie_008 | Features: 30 | Label: 0\n",
      "✅ Extracted 24 frames from ../videos/lie/trial_lie_020.mp4 → ../data/frames/trial_lie_020\n",
      "✅ Processed trial_lie_020 | Features: 30 | Label: 0\n",
      "✅ Extracted 63 frames from ../videos/lie/trial_lie_034.mp4 → ../data/frames/trial_lie_034\n",
      "✅ Processed trial_lie_034 | Features: 30 | Label: 0\n",
      "✅ Extracted 74 frames from ../videos/lie/trial_lie_018.mp4 → ../data/frames/trial_lie_018\n",
      "✅ Processed trial_lie_018 | Features: 30 | Label: 0\n",
      "✅ Extracted 81 frames from ../videos/lie/trial_lie_030.mp4 → ../data/frames/trial_lie_030\n",
      "✅ Processed trial_lie_030 | Features: 30 | Label: 0\n",
      "✅ Extracted 53 frames from ../videos/lie/trial_lie_024.mp4 → ../data/frames/trial_lie_024\n",
      "✅ Processed trial_lie_024 | Features: 30 | Label: 0\n",
      "✅ Extracted 64 frames from ../videos/lie/trial_lie_025.mp4 → ../data/frames/trial_lie_025\n",
      "✅ Processed trial_lie_025 | Features: 30 | Label: 0\n",
      "✅ Extracted 56 frames from ../videos/lie/trial_lie_031.mp4 → ../data/frames/trial_lie_031\n",
      "✅ Processed trial_lie_031 | Features: 30 | Label: 0\n",
      "✅ Extracted 79 frames from ../videos/lie/trial_lie_019.mp4 → ../data/frames/trial_lie_019\n",
      "✅ Processed trial_lie_019 | Features: 30 | Label: 0\n",
      "✅ Extracted 58 frames from ../videos/lie/trial_lie_027.mp4 → ../data/frames/trial_lie_027\n",
      "✅ Processed trial_lie_027 | Features: 30 | Label: 0\n",
      "✅ Extracted 94 frames from ../videos/lie/trial_lie_033.mp4 → ../data/frames/trial_lie_033\n",
      "✅ Processed trial_lie_033 | Features: 30 | Label: 0\n",
      "✅ Extracted 59 frames from ../videos/lie/trial_lie_032.mp4 → ../data/frames/trial_lie_032\n",
      "✅ Processed trial_lie_032 | Features: 30 | Label: 0\n",
      "✅ Extracted 62 frames from ../videos/lie/trial_lie_026.mp4 → ../data/frames/trial_lie_026\n",
      "✅ Processed trial_lie_026 | Features: 30 | Label: 0\n",
      "✅ Extracted 16 frames from ../videos/lie/trial_lie_003.mp4 → ../data/frames/trial_lie_003\n",
      "✅ Processed trial_lie_003 | Features: 30 | Label: 0\n",
      "✅ Extracted 94 frames from ../videos/lie/trial_lie_017.mp4 → ../data/frames/trial_lie_017\n",
      "✅ Processed trial_lie_017 | Features: 30 | Label: 0\n",
      "✅ Extracted 80 frames from ../videos/lie/trial_lie_016.mp4 → ../data/frames/trial_lie_016\n",
      "✅ Processed trial_lie_016 | Features: 30 | Label: 0\n",
      "✅ Extracted 134 frames from ../videos/lie/trial_lie_002.mp4 → ../data/frames/trial_lie_002\n",
      "✅ Processed trial_lie_002 | Features: 30 | Label: 0\n",
      "✅ Extracted 30 frames from ../videos/lie/trial_lie_014.mp4 → ../data/frames/trial_lie_014\n",
      "✅ Processed trial_lie_014 | Features: 30 | Label: 0\n",
      "✅ Extracted 52 frames from ../videos/lie/trial_lie_028.mp4 → ../data/frames/trial_lie_028\n",
      "✅ Processed trial_lie_028 | Features: 30 | Label: 0\n",
      "✅ Extracted 43 frames from ../videos/lie/trial_lie_029.mp4 → ../data/frames/trial_lie_029\n",
      "✅ Processed trial_lie_029 | Features: 30 | Label: 0\n",
      "✅ Extracted 37 frames from ../videos/lie/trial_lie_001.mp4 → ../data/frames/trial_lie_001\n",
      "✅ Processed trial_lie_001 | Features: 30 | Label: 0\n",
      "✅ Extracted 74 frames from ../videos/lie/trial_lie_015.mp4 → ../data/frames/trial_lie_015\n",
      "✅ Processed trial_lie_015 | Features: 30 | Label: 0\n",
      "✅ Extracted 63 frames from ../videos/lie/trial_lie_039.mp4 → ../data/frames/trial_lie_039\n",
      "✅ Processed trial_lie_039 | Features: 30 | Label: 0\n",
      "✅ Extracted 73 frames from ../videos/lie/trial_lie_011.mp4 → ../data/frames/trial_lie_011\n",
      "✅ Processed trial_lie_011 | Features: 30 | Label: 0\n",
      "✅ Extracted 115 frames from ../videos/lie/trial_lie_005.mp4 → ../data/frames/trial_lie_005\n",
      "✅ Processed trial_lie_005 | Features: 30 | Label: 0\n",
      "✅ Extracted 25 frames from ../videos/lie/trial_lie_004.mp4 → ../data/frames/trial_lie_004\n",
      "✅ Processed trial_lie_004 | Features: 30 | Label: 0\n",
      "✅ Extracted 63 frames from ../videos/lie/trial_lie_010.mp4 → ../data/frames/trial_lie_010\n",
      "✅ Processed trial_lie_010 | Features: 30 | Label: 0\n",
      "✅ Extracted 48 frames from ../videos/lie/trial_lie_038.mp4 → ../data/frames/trial_lie_038\n",
      "✅ Processed trial_lie_038 | Features: 30 | Label: 0\n",
      "✅ Extracted 39 frames from ../videos/lie/trial_lie_006.mp4 → ../data/frames/trial_lie_006\n",
      "✅ Processed trial_lie_006 | Features: 30 | Label: 0\n",
      "✅ Extracted 17 frames from ../videos/lie/trial_lie_012.mp4 → ../data/frames/trial_lie_012\n",
      "✅ Processed trial_lie_012 | Features: 30 | Label: 0\n",
      "✅ Extracted 41 frames from ../videos/lie/trial_lie_013.mp4 → ../data/frames/trial_lie_013\n",
      "✅ Processed trial_lie_013 | Features: 30 | Label: 0\n",
      "✅ Extracted 101 frames from ../videos/lie/trial_lie_007.mp4 → ../data/frames/trial_lie_007\n",
      "✅ Processed trial_lie_007 | Features: 30 | Label: 0\n",
      "✅ Extracted 54 frames from ../videos/lie/trial_lie_060.mp4 → ../data/frames/trial_lie_060\n",
      "✅ Processed trial_lie_060 | Features: 30 | Label: 0\n",
      "✅ Extracted 103 frames from ../videos/lie/trial_lie_048.mp4 → ../data/frames/trial_lie_048\n",
      "✅ Processed trial_lie_048 | Features: 30 | Label: 0\n",
      "✅ Extracted 50 frames from ../videos/lie/trial_lie_049.mp4 → ../data/frames/trial_lie_049\n",
      "✅ Processed trial_lie_049 | Features: 30 | Label: 0\n",
      "✅ Extracted 63 frames from ../videos/lie/trial_lie_061.mp4 → ../data/frames/trial_lie_061\n",
      "✅ Processed trial_lie_061 | Features: 30 | Label: 0\n",
      "✅ Extracted 86 frames from ../videos/lie/trial_lie_059.mp4 → ../data/frames/trial_lie_059\n",
      "✅ Processed trial_lie_059 | Features: 30 | Label: 0\n",
      "✅ Extracted 48 frames from ../videos/lie/trial_lie_058.mp4 → ../data/frames/trial_lie_058\n",
      "✅ Processed trial_lie_058 | Features: 30 | Label: 0\n",
      "✅ Extracted 73 frames from ../videos/truth/trial_truth_056.mp4 → ../data/frames/trial_truth_056\n",
      "✅ Processed trial_truth_056 | Features: 30 | Label: 1\n",
      "✅ Extracted 60 frames from ../videos/truth/trial_truth_042.mp4 → ../data/frames/trial_truth_042\n",
      "✅ Processed trial_truth_042 | Features: 30 | Label: 1\n",
      "✅ Extracted 44 frames from ../videos/truth/trial_truth_043.mp4 → ../data/frames/trial_truth_043\n",
      "✅ Processed trial_truth_043 | Features: 30 | Label: 1\n",
      "✅ Extracted 82 frames from ../videos/truth/trial_truth_057.mp4 → ../data/frames/trial_truth_057\n",
      "✅ Processed trial_truth_057 | Features: 30 | Label: 1\n",
      "✅ Extracted 68 frames from ../videos/truth/trial_truth_041.mp4 → ../data/frames/trial_truth_041\n",
      "✅ Processed trial_truth_041 | Features: 30 | Label: 1\n",
      "✅ Extracted 63 frames from ../videos/truth/trial_truth_055.mp4 → ../data/frames/trial_truth_055\n",
      "✅ Processed trial_truth_055 | Features: 30 | Label: 1\n",
      "✅ Extracted 52 frames from ../videos/truth/trial_truth_054.mp4 → ../data/frames/trial_truth_054\n",
      "✅ Processed trial_truth_054 | Features: 30 | Label: 1\n",
      "✅ Extracted 65 frames from ../videos/truth/trial_truth_040.mp4 → ../data/frames/trial_truth_040\n",
      "✅ Processed trial_truth_040 | Features: 30 | Label: 1\n",
      "✅ Extracted 42 frames from ../videos/truth/trial_truth_044.mp4 → ../data/frames/trial_truth_044\n",
      "✅ Processed trial_truth_044 | Features: 30 | Label: 1\n",
      "✅ Extracted 46 frames from ../videos/truth/trial_truth_050.mp4 → ../data/frames/trial_truth_050\n",
      "✅ Processed trial_truth_050 | Features: 30 | Label: 1\n",
      "✅ Extracted 63 frames from ../videos/truth/trial_truth_051.mp4 → ../data/frames/trial_truth_051\n",
      "✅ Processed trial_truth_051 | Features: 30 | Label: 1\n",
      "✅ Extracted 66 frames from ../videos/truth/trial_truth_045.mp4 → ../data/frames/trial_truth_045\n",
      "✅ Processed trial_truth_045 | Features: 30 | Label: 1\n",
      "✅ Extracted 63 frames from ../videos/truth/trial_truth_053.mp4 → ../data/frames/trial_truth_053\n",
      "✅ Processed trial_truth_053 | Features: 30 | Label: 1\n",
      "✅ Extracted 52 frames from ../videos/truth/trial_truth_047.mp4 → ../data/frames/trial_truth_047\n",
      "✅ Processed trial_truth_047 | Features: 30 | Label: 1\n",
      "✅ Extracted 74 frames from ../videos/truth/trial_truth_046.mp4 → ../data/frames/trial_truth_046\n",
      "✅ Processed trial_truth_046 | Features: 30 | Label: 1\n",
      "✅ Extracted 58 frames from ../videos/truth/trial_truth_052.mp4 → ../data/frames/trial_truth_052\n",
      "✅ Processed trial_truth_052 | Features: 30 | Label: 1\n",
      "✅ Extracted 63 frames from ../videos/truth/trial_truth_035.mp4 → ../data/frames/trial_truth_035\n",
      "✅ Processed trial_truth_035 | Features: 30 | Label: 1\n",
      "✅ Extracted 22 frames from ../videos/truth/trial_truth_021.mp4 → ../data/frames/trial_truth_021\n",
      "✅ Processed trial_truth_021 | Features: 30 | Label: 1\n",
      "✅ Extracted 49 frames from ../videos/truth/trial_truth_009.mp4 → ../data/frames/trial_truth_009\n",
      "✅ Processed trial_truth_009 | Features: 30 | Label: 1\n",
      "✅ Extracted 95 frames from ../videos/truth/trial_truth_008.mp4 → ../data/frames/trial_truth_008\n",
      "✅ Processed trial_truth_008 | Features: 30 | Label: 1\n",
      "✅ Extracted 15 frames from ../videos/truth/trial_truth_020.mp4 → ../data/frames/trial_truth_020\n",
      "✅ Processed trial_truth_020 | Features: 30 | Label: 1\n",
      "✅ Extracted 65 frames from ../videos/truth/trial_truth_034.mp4 → ../data/frames/trial_truth_034\n",
      "✅ Processed trial_truth_034 | Features: 30 | Label: 1\n",
      "✅ Extracted 62 frames from ../videos/truth/trial_truth_022.mp4 → ../data/frames/trial_truth_022\n",
      "✅ Processed trial_truth_022 | Features: 30 | Label: 1\n",
      "✅ Extracted 78 frames from ../videos/truth/trial_truth_036.mp4 → ../data/frames/trial_truth_036\n",
      "✅ Processed trial_truth_036 | Features: 30 | Label: 1\n",
      "✅ Extracted 46 frames from ../videos/truth/trial_truth_037.mp4 → ../data/frames/trial_truth_037\n",
      "✅ Processed trial_truth_037 | Features: 30 | Label: 1\n",
      "✅ Extracted 49 frames from ../videos/truth/trial_truth_023.mp4 → ../data/frames/trial_truth_023\n",
      "✅ Processed trial_truth_023 | Features: 30 | Label: 1\n",
      "✅ Extracted 54 frames from ../videos/truth/trial_truth_027.mp4 → ../data/frames/trial_truth_027\n",
      "✅ Processed trial_truth_027 | Features: 30 | Label: 1\n",
      "✅ Extracted 36 frames from ../videos/truth/trial_truth_033.mp4 → ../data/frames/trial_truth_033\n",
      "✅ Processed trial_truth_033 | Features: 30 | Label: 1\n",
      "✅ Extracted 78 frames from ../videos/truth/trial_truth_032.mp4 → ../data/frames/trial_truth_032\n",
      "✅ Processed trial_truth_032 | Features: 30 | Label: 1\n",
      "✅ Extracted 69 frames from ../videos/truth/trial_truth_026.mp4 → ../data/frames/trial_truth_026\n",
      "✅ Processed trial_truth_026 | Features: 30 | Label: 1\n",
      "✅ Extracted 15 frames from ../videos/truth/trial_truth_018.mp4 → ../data/frames/trial_truth_018\n",
      "✅ Processed trial_truth_018 | Features: 30 | Label: 1\n",
      "✅ Extracted 115 frames from ../videos/truth/trial_truth_030.mp4 → ../data/frames/trial_truth_030\n",
      "✅ Processed trial_truth_030 | Features: 30 | Label: 1\n",
      "✅ Extracted 48 frames from ../videos/truth/trial_truth_024.mp4 → ../data/frames/trial_truth_024\n",
      "✅ Processed trial_truth_024 | Features: 30 | Label: 1\n",
      "✅ Extracted 73 frames from ../videos/truth/trial_truth_025.mp4 → ../data/frames/trial_truth_025\n",
      "✅ Processed trial_truth_025 | Features: 30 | Label: 1\n",
      "✅ Extracted 38 frames from ../videos/truth/trial_truth_031.mp4 → ../data/frames/trial_truth_031\n",
      "✅ Processed trial_truth_031 | Features: 30 | Label: 1\n",
      "✅ Extracted 28 frames from ../videos/truth/trial_truth_019.mp4 → ../data/frames/trial_truth_019\n",
      "✅ Processed trial_truth_019 | Features: 30 | Label: 1\n",
      "✅ Extracted 28 frames from ../videos/truth/trial_truth_014.mp4 → ../data/frames/trial_truth_014\n",
      "✅ Processed trial_truth_014 | Features: 30 | Label: 1\n",
      "✅ Extracted 38 frames from ../videos/truth/trial_truth_028.mp4 → ../data/frames/trial_truth_028\n",
      "✅ Processed trial_truth_028 | Features: 30 | Label: 1\n",
      "✅ Extracted 48 frames from ../videos/truth/trial_truth_029.mp4 → ../data/frames/trial_truth_029\n",
      "✅ Processed trial_truth_029 | Features: 30 | Label: 1\n",
      "✅ Extracted 30 frames from ../videos/truth/trial_truth_001.mp4 → ../data/frames/trial_truth_001\n",
      "✅ Processed trial_truth_001 | Features: 30 | Label: 1\n",
      "✅ Extracted 77 frames from ../videos/truth/trial_truth_015.mp4 → ../data/frames/trial_truth_015\n",
      "✅ Processed trial_truth_015 | Features: 30 | Label: 1\n",
      "✅ Extracted 28 frames from ../videos/truth/trial_truth_003.mp4 → ../data/frames/trial_truth_003\n",
      "✅ Processed trial_truth_003 | Features: 30 | Label: 1\n",
      "✅ Extracted 10 frames from ../videos/truth/trial_truth_017.mp4 → ../data/frames/trial_truth_017\n",
      "✅ Processed trial_truth_017 | Features: 30 | Label: 1\n",
      "✅ Extracted 16 frames from ../videos/truth/trial_truth_016.mp4 → ../data/frames/trial_truth_016\n",
      "✅ Processed trial_truth_016 | Features: 30 | Label: 1\n",
      "✅ Extracted 43 frames from ../videos/truth/trial_truth_002.mp4 → ../data/frames/trial_truth_002\n",
      "✅ Processed trial_truth_002 | Features: 30 | Label: 1\n",
      "✅ Extracted 66 frames from ../videos/truth/trial_truth_006.mp4 → ../data/frames/trial_truth_006\n",
      "✅ Processed trial_truth_006 | Features: 30 | Label: 1\n",
      "✅ Extracted 61 frames from ../videos/truth/trial_truth_012.mp4 → ../data/frames/trial_truth_012\n",
      "✅ Processed trial_truth_012 | Features: 30 | Label: 1\n",
      "✅ Extracted 60 frames from ../videos/truth/trial_truth_013.mp4 → ../data/frames/trial_truth_013\n",
      "✅ Processed trial_truth_013 | Features: 30 | Label: 1\n",
      "✅ Extracted 154 frames from ../videos/truth/trial_truth_007.mp4 → ../data/frames/trial_truth_007\n",
      "✅ Processed trial_truth_007 | Features: 30 | Label: 1\n",
      "✅ Extracted 67 frames from ../videos/truth/trial_truth_039.mp4 → ../data/frames/trial_truth_039\n",
      "✅ Processed trial_truth_039 | Features: 30 | Label: 1\n",
      "✅ Extracted 88 frames from ../videos/truth/trial_truth_011.mp4 → ../data/frames/trial_truth_011\n",
      "✅ Processed trial_truth_011 | Features: 30 | Label: 1\n",
      "✅ Extracted 75 frames from ../videos/truth/trial_truth_005.mp4 → ../data/frames/trial_truth_005\n",
      "✅ Processed trial_truth_005 | Features: 30 | Label: 1\n",
      "✅ Extracted 175 frames from ../videos/truth/trial_truth_004.mp4 → ../data/frames/trial_truth_004\n",
      "✅ Processed trial_truth_004 | Features: 30 | Label: 1\n",
      "✅ Extracted 155 frames from ../videos/truth/trial_truth_010.mp4 → ../data/frames/trial_truth_010\n",
      "✅ Processed trial_truth_010 | Features: 30 | Label: 1\n",
      "✅ Extracted 40 frames from ../videos/truth/trial_truth_038.mp4 → ../data/frames/trial_truth_038\n",
      "✅ Processed trial_truth_038 | Features: 30 | Label: 1\n",
      "✅ Extracted 42 frames from ../videos/truth/trial_truth_060.mp4 → ../data/frames/trial_truth_060\n",
      "✅ Processed trial_truth_060 | Features: 30 | Label: 1\n",
      "✅ Extracted 52 frames from ../videos/truth/trial_truth_048.mp4 → ../data/frames/trial_truth_048\n",
      "✅ Processed trial_truth_048 | Features: 30 | Label: 1\n",
      "✅ Extracted 60 frames from ../videos/truth/trial_truth_049.mp4 → ../data/frames/trial_truth_049\n",
      "✅ Processed trial_truth_049 | Features: 30 | Label: 1\n",
      "✅ Extracted 58 frames from ../videos/truth/trial_truth_059.mp4 → ../data/frames/trial_truth_059\n",
      "✅ Processed trial_truth_059 | Features: 30 | Label: 1\n",
      "✅ Extracted 45 frames from ../videos/truth/trial_truth_058.mp4 → ../data/frames/trial_truth_058\n",
      "✅ Processed trial_truth_058 | Features: 30 | Label: 1\n"
     ]
    }
   ],
   "source": [
    "video_root = \"../videos\"\n",
    "out_csv = \"../data/deception_dataset.csv\"\n",
    "\n",
    "for class_name in [\"lie\", \"truth\"]:\n",
    "    label = 0 if class_name == \"lie\" else 1\n",
    "    folder = os.path.join(video_root, class_name)\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        print(\"Folder missing:\", folder)\n",
    "        continue\n",
    "\n",
    "    for video_file in os.listdir(folder):\n",
    "\n",
    "        # ignore system files\n",
    "        if video_file.startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(folder, video_file)\n",
    "\n",
    "        try:\n",
    "            process_video_to_features(\n",
    "                video_path=video_path,\n",
    "                class_label=label,\n",
    "                out_csv=out_csv,\n",
    "                fps=2\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7f7be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Trained!\n",
      "\n",
      "Accuracy: 0.88\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        14\n",
      "           1       0.90      0.82      0.86        11\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.88      0.87      0.88        25\n",
      "weighted avg       0.88      0.88      0.88        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/deception_dataset.csv\")\n",
    "\n",
    "# Separate features & labels\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test performance\n",
    "preds = clf.predict(X_test)\n",
    "print(\"✅ Model Trained!\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e3ef288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lie/Truth classifier saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"../models/deception_classifier.pkl\")\n",
    "print(\"✅ Lie/Truth classifier saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abac1ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 37 frames from ../videos/lie/trial_lie_001.mp4 → ../data/frames/trial_lie_001\n",
      "✅ Processed trial_lie_001 | Features: 30 | Label: 1\n"
     ]
    }
   ],
   "source": [
    "X_sample = process_video_to_features(\n",
    "    video_path=\"../videos/lie/trial_lie_001.mp4\",\n",
    "    class_label=1,     # TRUTH = 1\n",
    "    out_csv=\"__temp.csv\",\n",
    "    fps=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21c22551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: LIE\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"../models/deception_classifier.pkl\")\n",
    "\n",
    "# Convert X_sample to DataFrame with same column names as training data\n",
    "X_input = pd.DataFrame([X_sample], columns=clf.feature_names_in_)\n",
    "\n",
    "prediction = clf.predict(X_input)\n",
    "print(\"Prediction:\", \"LIE\" if prediction[0] == 0 else \"TRUTH\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
